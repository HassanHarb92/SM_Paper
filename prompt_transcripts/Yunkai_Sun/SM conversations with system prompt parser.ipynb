{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a62520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Preprompt for Code Understanding and Modification**\n",
    "#\n",
    "# You are being provided with a Python script that processes conversation transcripts to extract and analyze specific information related to Socratic methods. Your task is to understand the structure and functionality of the code and modify it as needed. This may include improving performance, adding new features, or adapting it to different requirements.\n",
    "#\n",
    "# Please carefully review the code provided below, paying special attention to the following key aspects:\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### **Functionality Overview:**\n",
    "#\n",
    "# #### **1. Conversation Parsing:**\n",
    "#\n",
    "# - **Transcript Reading:**\n",
    "#   - The script reads a chat transcript from a file specified by the user.\n",
    "#   - It checks if the conversation starts with a specific Socratic system prompt using the `check_socratic_system_prompt` function.\n",
    "#\n",
    "# - **Segmentation into Pairs:**\n",
    "#   - The conversation is segmented into pairs of user prompts and assistant responses.\n",
    "#   - It preserves the original paragraph structure of the conversation.\n",
    "#\n",
    "# #### **2. Response Segmentation:**\n",
    "#\n",
    "# - **Assistant Response Categories:**\n",
    "#   - Assistant responses are further segmented into four specific categories:\n",
    "#     - **Selected Principle(s)**\n",
    "#     - **Socratic Reformulation**\n",
    "#     - **Self-Query and Answer**\n",
    "#     - **Follow-Up Questions**\n",
    "#   - The segmentation preserves paragraph structure within each category.\n",
    "#\n",
    "# #### **3. Socratic Methods Identification:**\n",
    "#\n",
    "# - **Method Sequence Extraction:**\n",
    "#   - The script identifies sequences of Socratic methods within texts using a predefined list.\n",
    "#   - It handles various formats and connectors between methods (e.g., \"â†’\", \"-&gt;\", \",\", \"/\", \"and\").\n",
    "#\n",
    "# - **Application Areas:**\n",
    "#   - Socratic methods are identified in:\n",
    "#     - Selected principles\n",
    "#     - Socratic reformulations\n",
    "#     - Follow-up questions\n",
    "#\n",
    "# #### **4. Similarity Computation:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Computes the similarity between user prompts and the assistant's previous follow-up questions.\n",
    "#\n",
    "# - **Methodology:**\n",
    "#   - Uses TF-IDF vectorization and cosine similarity for comparison.\n",
    "#   - Incorporates text preprocessing steps such as lowercasing, punctuation removal, tokenization, and stopword removal.\n",
    "#\n",
    "# #### **5. Processing and Exporting Results:**\n",
    "#\n",
    "# - **Data Structuring:**\n",
    "#   - Processes conversation data to build structured representations of each conversation turn.\n",
    "#   - Associates extracted Socratic methods and similarity scores with each turn.\n",
    "#\n",
    "# - **Result Exporting:**\n",
    "#   - Exports results in either a verbose or concise format.\n",
    "#     - **Verbose:** Includes detailed conversation data and comparisons.\n",
    "#     - **Concise:** Displays key information such as Socratic methods and similarity scores.\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### **Key Functions:**\n",
    "#\n",
    "# #### **1. `parse_assistant_response(response_text)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Segments an assistant's response into the four predefined categories.\n",
    "# - **Features:**\n",
    "#   - Preserves paragraph structure within each category.\n",
    "#   - Returns a dictionary with each category as keys.\n",
    "#\n",
    "# #### **2. `segment_conversation_preserve_paragraphs(file_path)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Reads the conversation transcript from a file and segments it into user-assistant pairs.\n",
    "# - **Features:**\n",
    "#   - Preserves the original paragraph structure.\n",
    "#   - Calls `parse_assistant_response` for each assistant response.\n",
    "#\n",
    "# #### **3. `identify_socratic_sequence(text, socratic_methods)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Identifies the sequence of Socratic methods in a given text.\n",
    "# - **Features:**\n",
    "#   - Handles various separators and connectors.\n",
    "#   - Performs case-insensitive matching.\n",
    "#   - Filters valid Socratic methods from the provided list.\n",
    "#\n",
    "# #### **4. `parse_followup_questions(followup_text)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Parses the \"Follow-Up Questions\" section into individual questions.\n",
    "# - **Features:**\n",
    "#   - Extracts question numbers, associated Socratic methods, and question texts.\n",
    "#   - Handles various formatting scenarios.\n",
    "#\n",
    "# #### **5. `process_conversation(paired_conversation, socratic_methods)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Processes the conversation pairs and builds data structures.\n",
    "# - **Features:**\n",
    "#   - Extracts and associates assistant methods and segmented responses.\n",
    "#   - Prepares data for similarity computation.\n",
    "#\n",
    "# #### **6. `compute_similarities(conversation_data)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Computes similarities between user prompts and assistant's previous follow-up questions.\n",
    "# - **Features:**\n",
    "#   - Utilizes text preprocessing and cosine similarity calculation.\n",
    "#   - Associates highest similarity scores with conversation turns.\n",
    "#\n",
    "# #### **7. `compute_similarity(text1, text2)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Computes the cosine similarity between two text strings after preprocessing.\n",
    "# - **Features:**\n",
    "#   - Uses NLTK for text processing and scikit-learn for vectorization and similarity computation.\n",
    "#\n",
    "# #### **8. `export_results(conversation_data)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Exports the results by printing specified information.\n",
    "# - **Features:**\n",
    "#   - Displays Socratic methods and similarity scores.\n",
    "#   - Provides a concise summary of each conversation turn.\n",
    "#\n",
    "# #### **9. `export_results_verbose(conversation_data)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Exports detailed conversation data and comparison results.\n",
    "# - **Features:**\n",
    "#   - Includes all segmented assistant responses and associated information.\n",
    "#\n",
    "# #### **10. `check_socratic_system_prompt(file_path)`:**\n",
    "#\n",
    "# - **Purpose:**\n",
    "#   - Checks if the conversation file starts with the Socratic system prompt.\n",
    "# - **Features:**\n",
    "#   - Searches for specific keywords at the beginning of the file.\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### **Points to Consider:**\n",
    "#\n",
    "# #### **1. Text Preprocessing:**\n",
    "#\n",
    "# - **Enhancements:**\n",
    "#   - Ensure text preprocessing in `compute_similarity` is thorough and efficient.\n",
    "#   - Consider additional steps (e.g., lemmatization) to improve similarity accuracy.\n",
    "#\n",
    "# #### **2. Regex Patterns:**\n",
    "#\n",
    "# - **Review:**\n",
    "#   - Refine regular expressions used in parsing functions.\n",
    "#   - Ensure they handle various formats and connectors correctly.\n",
    "#   - Pay attention to edge cases and inconsistencies in conversation transcripts.\n",
    "#\n",
    "# #### **3. Error Handling:**\n",
    "#\n",
    "# - **Robustness:**\n",
    "#   - Verify that functions handle unexpected input gracefully.\n",
    "#   - Implement error checks or exception handling where necessary.\n",
    "#   - Prevent index errors and ensure lists are not modified unexpectedly (e.g., cautious use of `del` statements).\n",
    "#\n",
    "# #### **4. Extensibility:**\n",
    "#\n",
    "# - **Adaptability:**\n",
    "#   - Consider adapting the script for additional categories or conversational structures.\n",
    "#   - Modularize code for reusability and scalability.\n",
    "#   - Facilitate easy updates to the list of Socratic methods.\n",
    "#\n",
    "# #### **5. Code Organization and Readability:**\n",
    "#\n",
    "# - **Best Practices:**\n",
    "#   - Refactor code to enhance readability and maintainability.\n",
    "#   - Use descriptive variable and function names.\n",
    "#   - Ensure consistent coding style and formatting.\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### **Modification Guidelines:**\n",
    "#\n",
    "# #### **1. Maintain Existing Functionality:**\n",
    "#\n",
    "# - **Integrity:**\n",
    "#   - Do not break current behavior of the script.\n",
    "#   - Preserve data parsing and analysis integrity.\n",
    "#\n",
    "# #### **2. Improve Readability and Efficiency:**\n",
    "#\n",
    "# - **Optimization:**\n",
    "#   - Refactor code to enhance clarity.\n",
    "#   - Optimize performance without sacrificing readability.\n",
    "#   - Reduce redundancy and simplify complex logic where possible.\n",
    "#\n",
    "# #### **3. Document Changes:**\n",
    "#\n",
    "# - **Clarity:**\n",
    "#   - Include comments explaining modifications or additions.\n",
    "#   - Update docstrings to reflect any changes in function behavior or parameters.\n",
    "#   - Maintain thorough documentation for future reference.\n",
    "#\n",
    "# #### **4. Testing:**\n",
    "#\n",
    "# - **Validation:**\n",
    "#   - Test the script with various conversation transcripts.\n",
    "#   - Ensure correct identification of Socratic methods.\n",
    "#   - Verify that similarity scores are accurate and meaningful.\n",
    "#\n",
    "# #### **5. Compatibility and Dependencies:**\n",
    "#\n",
    "# - **Reliability:**\n",
    "#   - Ensure all dependencies (e.g., NLTK, scikit-learn) are properly handled.\n",
    "#   - Check compatibility with different Python versions.\n",
    "#   - Provide clear instructions for setting up the environment if necessary.\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### **Socratic Methods List:**\n",
    "#\n",
    "# The script uses the following list of Socratic methods for identification:\n",
    "#\n",
    "# - **Definition**\n",
    "# - **Generalization**\n",
    "# - **Induction**\n",
    "# - **Elenchus**\n",
    "# - **Hypothesis Elimination**\n",
    "# - **Maieutics**\n",
    "# - **Dialectic**\n",
    "# - **Recollection**\n",
    "# - **Analogy**\n",
    "# - **Irony**\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# **Note:** Ensure that you thoroughly understand each component of the script before making modifications. Pay close attention to how functions interact and how data flows through the program. Your goal is to enhance the script while maintaining its core functionality and improving its overall quality.\n",
    "#\n",
    "# --- End of Preprompt ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe2eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yunkai.sun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yunkai.sun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Computes similarity between two texts using TF-IDF vectorization and cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): First text string.\n",
    "        text2 (str): Second text string.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity score between 0 and 1.\n",
    "    \"\"\"\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # Ensure NLTK stopwords are downloaded\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess(text):\n",
    "        # Lowercase\n",
    "        text = text.lower()\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Tokenize\n",
    "        words = nltk.word_tokenize(text)\n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        # Rejoin into a string\n",
    "        return ' '.join(words)\n",
    "\n",
    "    # Preprocess both texts\n",
    "    text1 = preprocess(text1)\n",
    "    text2 = preprocess(text2)\n",
    "\n",
    "    if not text1 or not text2:\n",
    "        return 0.0  # If either text is empty after preprocessing\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    return cosine_sim[0][1]\n",
    "\n",
    "def parse_assistant_response(response_text):\n",
    "    \"\"\"\n",
    "    Further segments an assistant's response into four specific categories:\n",
    "      - Selected Principle(s)\n",
    "      - Socratic Reformulation\n",
    "      - Self-Query and Answer\n",
    "      - Follow-Up Questions\n",
    "\n",
    "    Preserves paragraph structure for each category.\n",
    "    Returns a dictionary where each key corresponds to one of these categories,\n",
    "    and the value is a string containing that segment of text.\n",
    "\n",
    "    If a category is not found, its value will be an empty string.\n",
    "    \"\"\"\n",
    "\n",
    "    categories = {\n",
    "        \"Selected Principle(s)\": [],\n",
    "        \"Socratic Reformulation\": [],\n",
    "        \"Self-Query and Answer\": [],\n",
    "        \"Follow-Up Questions\": []\n",
    "    }\n",
    "    current_category = None\n",
    "\n",
    "    # Split the entire assistant response into lines\n",
    "    lines = response_text.split(\"\\n\")\n",
    "\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "\n",
    "        # Check for possible category headers. \n",
    "        # Use \"in\" rather than \"startswith\" to handle lines like \"Argo: Selected Principle(s): ...\".\n",
    "        if \"Selected Principle(s):\" in stripped_line:\n",
    "            current_category = \"Selected Principle(s)\"\n",
    "            categories[current_category].append(stripped_line)\n",
    "        elif \"Socratic Reformulation:\" in stripped_line:\n",
    "            current_category = \"Socratic Reformulation\"\n",
    "            categories[current_category].append(stripped_line)\n",
    "        elif \"Self-Query and Answer:\" in stripped_line:\n",
    "            current_category = \"Self-Query and Answer\"\n",
    "            categories[current_category].append(stripped_line)\n",
    "        elif \"Follow-Up Questions\" in stripped_line:\n",
    "            current_category = \"Follow-Up Questions\"\n",
    "            categories[current_category].append(stripped_line)\n",
    "        else:\n",
    "            # If we are currently in one of the known categories, append the line there.\n",
    "            if current_category:\n",
    "                categories[current_category].append(line)\n",
    "\n",
    "    # Convert each list of lines back into a single string (preserving original paragraph structure)\n",
    "    segmented_response = {}\n",
    "    for cat, cat_lines in categories.items():\n",
    "        segmented_response[cat] = \"\\n\".join(cat_lines).strip()\n",
    "\n",
    "    return segmented_response\n",
    "\n",
    "\n",
    "def segment_conversation_preserve_paragraphs(file_path):\n",
    "    \"\"\"\n",
    "    Reads a chat transcript from a file and segments it into\n",
    "    pairs of (user_prompt, assistant_prompt, segmented_assistant_response).\n",
    "    The function assumes:\n",
    "      - A user prompt always starts with a line beginning with \"User:\" or \"You:\".\n",
    "      - An assistant prompt always starts with a line beginning with \"Argo:\" or \"Assistant:\".\n",
    "      - Each user prompt is matched to the next assistant prompt in chronological order.\n",
    "\n",
    "    This version preserves the original paragraph structure by joining lines\n",
    "    with newline characters, rather than spaces.\n",
    "\n",
    "    Additionally, for each assistant_prompt, we further segment the text based on:\n",
    "      - Selected Principle(s)\n",
    "      - Socratic Reformulation\n",
    "      - Self-Query and Answer\n",
    "      - Follow-Up Questions\n",
    "\n",
    "    Returns a list of tuples:\n",
    "      [\n",
    "        (\n",
    "          \"User Prompt i\", user_text,\n",
    "          \"Assistant Prompt i\", assistant_text,\n",
    "          {\n",
    "            \"Selected Principle(s)\": ...,\n",
    "            \"Socratic Reformulation\": ...,\n",
    "            \"Self-Query and Answer\": ...,\n",
    "            \"Follow-Up Questions\": ...\n",
    "          }\n",
    "        ),\n",
    "        ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "\n",
    "    conversation_pairs = []\n",
    "    current_user_text = []\n",
    "    current_assistant_text = []\n",
    "    reading_user = False\n",
    "    reading_assistant = False\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            stripped_line = line.rstrip(\"\\n\")\n",
    "\n",
    "            # Check if the line begins with a user marker\n",
    "            if stripped_line.startswith(\"User:\") or stripped_line.startswith(\"You:\"):\n",
    "                # If we were reading assistant text, that means we ended an assistant block\n",
    "                if reading_assistant and current_assistant_text and current_user_text:\n",
    "                    # Save the finished pair\n",
    "                    conversation_pairs.append(\n",
    "                        (\"\\n\".join(current_user_text).strip(), \"\\n\".join(current_assistant_text).strip())\n",
    "                    )\n",
    "                    current_assistant_text = []\n",
    "\n",
    "                # Start reading a new user block\n",
    "                reading_user = True\n",
    "                reading_assistant = False\n",
    "                current_user_text = [stripped_line]\n",
    "\n",
    "            # Check if the line begins with an assistant marker\n",
    "            elif stripped_line.startswith(\"Argo:\") or stripped_line.startswith(\"Assistant:\"):\n",
    "                # If we were reading user text, that means we ended a user block\n",
    "                if reading_user and current_user_text:\n",
    "                    reading_user = False\n",
    "                    reading_assistant = True\n",
    "                    current_assistant_text = [stripped_line]\n",
    "                else:\n",
    "                    # If we are already reading assistant text, continue appending\n",
    "                    reading_assistant = True\n",
    "                    current_assistant_text.append(stripped_line)\n",
    "\n",
    "            else:\n",
    "                # Continue reading current block\n",
    "                if reading_user:\n",
    "                    current_user_text.append(stripped_line)\n",
    "                elif reading_assistant:\n",
    "                    current_assistant_text.append(stripped_line)\n",
    "\n",
    "        # Handle the last pair if the file ends on an assistant block\n",
    "        if current_user_text and current_assistant_text:\n",
    "            conversation_pairs.append(\n",
    "                (\"\\n\".join(current_user_text).strip(), \"\\n\".join(current_assistant_text).strip())\n",
    "            )\n",
    "\n",
    "    # Assign sequential numbering and parse each assistant response into its categories\n",
    "    numbered_pairs = []\n",
    "    for i, (user, assistant) in enumerate(conversation_pairs, start=1):\n",
    "        segmented_assistant_response = parse_assistant_response(assistant)\n",
    "        numbered_pairs.append(\n",
    "            (f\"User Prompt {i}\",\n",
    "             user,\n",
    "             f\"Assistant Prompt {i}\",\n",
    "             assistant,\n",
    "             segmented_assistant_response)\n",
    "        )\n",
    "\n",
    "    return numbered_pairs\n",
    "\n",
    "def parse_followup_questions(followup_text):\n",
    "    \"\"\"\n",
    "    Parses the 'Follow-Up Questions' section into a list of dictionaries,\n",
    "    each containing the question number, Socratic methods, and question text.\n",
    "\n",
    "    Args:\n",
    "        followup_text (str): The text containing all follow-up questions.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries with keys:\n",
    "            - 'number': The question number.\n",
    "            - 'methods': A list of Socratic methods identified in the header.\n",
    "            - 'text': The question text without the header.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    lines = followup_text.strip().split(\"\\n\")\n",
    "\n",
    "    # Pattern to match lines starting with a number followed by a period\n",
    "    question_start_pattern = re.compile(r\"^(\\d+)\\.\\s*(.*)\")\n",
    "\n",
    "    questions = []\n",
    "    current_question = []\n",
    "    current_methods = []\n",
    "    question_number = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "\n",
    "        match = question_start_pattern.match(line)\n",
    "        if match:\n",
    "            # Save the previous question if it exists\n",
    "            if current_question:\n",
    "                questions.append({\n",
    "                    'number': question_number,\n",
    "                    'methods': current_methods,\n",
    "                    'text': ' '.join(current_question).strip()\n",
    "                })\n",
    "                current_question = []\n",
    "                current_methods = []\n",
    "\n",
    "            question_number = match.group(1)\n",
    "            header = match.group(2)\n",
    "\n",
    "            # Identify Socratic methods in the header\n",
    "            methods = identify_socratic_sequence(header, socratic_methods)\n",
    "            current_methods = methods\n",
    "\n",
    "            # Remove the Socratic methods and numbering from the question text\n",
    "            question_text = header.split(':', 1)[-1].strip() if ':' in header else ''\n",
    "            if question_text:\n",
    "                current_question.append(question_text)\n",
    "        else:\n",
    "            current_question.append(line)\n",
    "\n",
    "    # Add the last question\n",
    "    if current_question:\n",
    "        questions.append({\n",
    "            'number': question_number,\n",
    "            'methods': current_methods,\n",
    "            'text': ' '.join(current_question).strip()\n",
    "        })\n",
    "    del questions[0]\n",
    "    return questions\n",
    "\n",
    "def identify_socratic_sequence(text, socratic_methods):\n",
    "    \"\"\"\n",
    "    Identifies the sequence of Socratic methods in a given text using the provided list of keywords.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which to extract the Socratic method sequence.\n",
    "        socratic_methods (list): A list of Socratic method keywords.\n",
    "\n",
    "    Returns:\n",
    "        A list of Socratic methods identified in the text in the order they appear.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    methods = []\n",
    "\n",
    "    # Remove any leading numbering or identifiers (e.g., '1. ', 'Argo: ')\n",
    "    sequence_part = re.sub(r'^\\s*(\\d+\\.\\s*|\\w+:\\s*)?', '', text)\n",
    "\n",
    "    # Extract the part before the colon, if present\n",
    "    sequence_part = sequence_part.split(':')[0]\n",
    "\n",
    "    # Replace ' and ' with commas\n",
    "    sequence_part = sequence_part.replace(' and ', ', ')\n",
    "\n",
    "    # Split the sequence based on connectors\n",
    "    methods_raw = re.split(r'\\s*(?:â†’|->|,|/|and)\\s*', sequence_part)\n",
    "\n",
    "    # Filter out valid Socratic methods (case-insensitive)\n",
    "    for method in methods_raw:\n",
    "        method_clean = method.strip()\n",
    "        for sm in socratic_methods:\n",
    "            if method_clean.lower() == sm.lower():\n",
    "                methods.append(sm)\n",
    "                break\n",
    "\n",
    "    return methods\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0dc8f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt 1:\n",
      "User: yunkai.sun\n",
      "Time: 2/22/2025, 5:56:12 PM\n",
      "Argo Version: v1.3.0\n",
      "-----------------------------------------------\n",
      "\n",
      "No previous follow-up questions to compare with.\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 2 Socratic Methods: []\n",
      "  Question 3 Socratic Methods: []\n",
      "  Question 4 Socratic Methods: []\n",
      "  Question 5 Socratic Methods: []\n",
      "  Question 6 Socratic Methods: []\n",
      "  Question 7 Socratic Methods: []\n",
      "  Question 8 Socratic Methods: []\n",
      "  Question 9 Socratic Methods: []\n",
      "  Question 10 Socratic Methods: []\n",
      "  Question 4 Socratic Methods: []\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 2:\n",
      "You: Choose suitable electrolyte system and deposition parameters for Fe-Pt electrodeposition.\n",
      "\n",
      "Comparing User Prompt 2 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: o\tUser Input: \"What do all strong acids have in common? (Generalization)\" o\tFollow-Up Questions: ï‚§\t\"How do these properties extend to acids beyond those commonly studied?\" ï‚§\t\"What exceptions exist to this generalization, and how do they inform our understanding?\" ï‚§\t\"If a new acid were discovered, what tests would confirm its classification as strong?\"\n",
      "Socratic Methods: []\n",
      "Similarity score: 0.0000\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Definition', 'Hypothesis Elimination']\n",
      "  Question 2 Socratic Methods: ['Induction', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Recollection']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 3:\n",
      "You: Make sure you consider different orders of SM chain of thoughts, there are only first order chain of thoughts in the answer.\n",
      "\n",
      "Comparing User Prompt 3 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: How do we define the optimal electrolyte composition for Fe-Pt electrodeposition, and what experimental methods can we use to test different compositions for effectiveness and stability?\n",
      "Socratic Methods: ['Definition', 'Hypothesis Elimination']\n",
      "Similarity score: 0.0339\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Definition', 'Induction', 'Hypothesis Elimination']\n",
      "  Question 2 Socratic Methods: ['Induction', 'Elenchus', 'Dialectic']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Recollection', 'Analogy']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 4:\n",
      "You: What general principles of electrodeposition apply to the Fe-Pt system, and how do these principles align with historical data or prior knowledge about similar bimetallic systems? Can we draw analogies to other electrodeposition processes to gain insights into optimizing Fe-Pt deposition?\n",
      "\n",
      "Comparing User Prompt 4 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: What general principles of electrodeposition apply to the Fe-Pt system, and how do these principles align with historical data or prior knowledge about similar bimetallic systems? Can we draw analogies to other electrodeposition processes to gain insights into optimizing Fe-Pt deposition?\n",
      "Socratic Methods: ['Generalization', 'Recollection', 'Analogy']\n",
      "Similarity score: 1.0000\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Generalization', 'Induction', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Analogy', 'Elenchus', 'Hypothesis Elimination']\n",
      "  Question 3 Socratic Methods: ['Recollection', 'Definition', 'Dialectic']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 5:\n",
      "You: How does prior knowledge about the electrodeposition of similar bimetallic systems help define the optimal conditions for Fe-Pt deposition? Based on those knowledge, what would be the specific optimal deposition conditions (electrolyte constitution and control parameters) for Fe-Pt deposition?\n",
      "\n",
      "Comparing User Prompt 5 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: How does prior knowledge about the electrodeposition of similar bimetallic systems help define the optimal conditions for Fe-Pt deposition? In what ways do these conditions align or conflict with theoretical predictions, and how can we reconcile any discrepancies?\n",
      "Socratic Methods: ['Recollection', 'Definition', 'Dialectic']\n",
      "Similarity score: 0.5503\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Definition', 'Analogy', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 6:\n",
      "You: The answers regarding current densities, deposition time, and electrolyte composition are not specific enough. Potentiostatic conditions were also not considered.\n",
      "\n",
      "Comparing User Prompt 6 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: How do we define the optimal electrolyte composition and deposition parameters for Fe-Pt electrodeposition, and what evidence can we gather from specific cases to form hypotheses about their effectiveness? How can we test these hypotheses to eliminate less effective combinations?\n",
      "Socratic Methods: ['Definition', 'Induction', 'Hypothesis Elimination']\n",
      "Similarity score: 0.1274\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Definition', 'Analogy', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 7:\n",
      "You: What specific experimental results from Fe-Pt electrodeposition can be used to hypothesize the optimal current densities and potentials, and how can these hypotheses be tested and refined? How does historical data support or challenge these hypotheses?\n",
      "\n",
      "Comparing User Prompt 7 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: What specific experimental results from Fe-Pt electrodeposition can be used to hypothesize the optimal current densities and potentials, and how can these hypotheses be tested and refined? How does historical data support or challenge these hypotheses?\n",
      "Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "Similarity score: 1.0000\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Definition', 'Analogy', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 8:\n",
      "You: What general principles from electrodeposition can be applied to the Fe-Pt system, and how do these principles align or conflict with theoretical predictions? How can specific experimental cases be used to induce broader conclusions about optimal deposition conditions?\n",
      "\n",
      "Comparing User Prompt 8 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: What general principles from electrodeposition can be applied to the Fe-Pt system, and how do these principles align or conflict with theoretical predictions? How can specific experimental cases be used to induce broader conclusions about optimal deposition conditions?\n",
      "Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "Similarity score: 1.0000\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Definition', 'Analogy', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 9:\n",
      "You: Reflect on our discussions, and give a very specific exploration approach for designing exploration space for Fe-Pt electrodeposition electrolyte concentrations and control parameters.\n",
      "\n",
      "Comparing User Prompt 9 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: Based on specific cases of successful Fe-Pt electrodeposition, what trends can we observe in the deposition parameters, and are there any inconsistencies or challenges that arise when applying these parameters to new systems?\n",
      "Socratic Methods: ['Induction', 'Elenchus']\n",
      "Similarity score: 0.1656\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Definition', 'Analogy', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 10:\n",
      "You: From this exploration grid, what general principles from electrodeposition can be applied to the Fe-Pt system, and how do these principles align or conflict with theoretical predictions? How can specific experimental cases be used to induce broader conclusions about optimal deposition conditions?\n",
      "\n",
      "Comparing User Prompt 10 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: What general principles from electrodeposition can be applied to the Fe-Pt system, and how do these principles align or conflict with theoretical predictions? How can specific experimental cases be used to induce broader conclusions about optimal deposition conditions?\n",
      "Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "Similarity score: 0.9238\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Definition', 'Analogy', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 11:\n",
      "You: From different electrochemical theories, explain the reason behind the \"Alignment and Conflict with Theoretical Predictions\" provided\n",
      "\n",
      "Comparing User Prompt 11 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: How does prior knowledge about the electrodeposition of similar bimetallic systems help define the optimal conditions for Fe-Pt deposition? In what ways do these conditions align or conflict with theoretical predictions, and how can we reconcile any discrepancies?\n",
      "Socratic Methods: ['Recollection', 'Definition', 'Dialectic']\n",
      "Similarity score: 0.1087\n",
      "\n",
      "Socratic Methods of Follow-Up Questions:\n",
      "  Question 1 Socratic Methods: ['Induction', 'Hypothesis Elimination', 'Recollection']\n",
      "  Question 2 Socratic Methods: ['Definition', 'Analogy', 'Elenchus']\n",
      "  Question 3 Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 12:\n",
      "You: Summarize our discussion, provide a full list of specific expectations and experimental details on the exploration of Fe-Pt electrodeposition system based on your design.\n",
      "\n",
      "Comparing User Prompt 12 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: What general principles from electrodeposition can be applied to the Fe-Pt system, and how do these principles align or conflict with theoretical predictions? How can specific experimental cases be used to induce broader conclusions about optimal deposition conditions?\n",
      "Socratic Methods: ['Generalization', 'Dialectic', 'Induction']\n",
      "Similarity score: 0.1578\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 13:\n",
      "You: Based on discussions and summary, which hypothesis can we test during this exploration, and how should we extend this work in terms of applications and theoretical research involving electrodeposition?\n",
      "\n",
      "Comparing User Prompt 13 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: How do we define the optimal electrolyte composition for Fe-Pt electrodeposition, and what experimental methods can we use to test different compositions for effectiveness and stability?\n",
      "Socratic Methods: ['Definition', 'Hypothesis Elimination']\n",
      "Similarity score: 0.0778\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User Prompt 14:\n",
      "You: That's everything I need, awesome! Good bot :D\n",
      "\n",
      "Comparing User Prompt 14 to assistant's previous follow-up questions...\n",
      "\n",
      "Most similar follow-up question:\n",
      "Text: o\tUser Input: \"What do all strong acids have in common? (Generalization)\" o\tFollow-Up Questions: ï‚§\t\"How do these properties extend to acids beyond those commonly studied?\" ï‚§\t\"What exceptions exist to this generalization, and how do they inform our understanding?\" ï‚§\t\"If a new acid were discovered, what tests would confirm its classification as strong?\"\n",
      "Socratic Methods: []\n",
      "Similarity score: 0.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def process_conversation(paired_conversation, socratic_methods):\n",
    "    \"\"\"\n",
    "    Processes the conversation and builds data structures.\n",
    "\n",
    "    Args:\n",
    "        paired_conversation (list): The list of conversation pairs.\n",
    "        socratic_methods (list): List of Socratic method keywords.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of conversation data dictionaries.\n",
    "    \"\"\"\n",
    "    conversation_data = []\n",
    "\n",
    "    for idx, item in enumerate(paired_conversation):\n",
    "        user_label, user_text, asst_label, asst_text, segmented = item\n",
    "\n",
    "        # Remove 'You: ' from user_text for similarity comparison\n",
    "        clean_user_text = re.sub(r'^You:\\s*', '', user_text).strip()\n",
    "\n",
    "        # Process assistant's segmented response\n",
    "        assistant_methods = {}\n",
    "\n",
    "        for cat, seg_text in segmented.items():\n",
    "            if cat in [\"Selected Principle(s)\", \"Follow-Up Questions\", \"Socratic Reformulation\"] and seg_text:\n",
    "                if cat == \"Selected Principle(s)\":\n",
    "                    seg_text_clean = re.sub(r'^.*Selected Principle\\(s\\):\\s*', '', seg_text)\n",
    "                    methods = identify_socratic_sequence(seg_text_clean, socratic_methods)\n",
    "                    assistant_methods['Selected Principle(s)'] = methods\n",
    "                elif cat == \"Follow-Up Questions\":\n",
    "                    followup_questions = parse_followup_questions(seg_text)\n",
    "                    assistant_methods['Follow-Up Questions'] = followup_questions\n",
    "                elif cat == \"Socratic Reformulation\":\n",
    "                    methods = identify_socratic_sequence(seg_text, socratic_methods)\n",
    "                    assistant_methods['Socratic Reformulation'] = methods\n",
    "\n",
    "        # Build the data for this conversation turn\n",
    "        conversation_data.append({\n",
    "            'idx': idx,\n",
    "            'user_label': user_label,\n",
    "            'user_text': user_text,\n",
    "            'clean_user_text': clean_user_text,\n",
    "            'asst_label': asst_label,\n",
    "            'asst_text': asst_text,\n",
    "            'segmented': segmented,\n",
    "            'assistant_methods': assistant_methods,\n",
    "        })\n",
    "\n",
    "    return conversation_data\n",
    "\n",
    "def compute_similarities(conversation_data):\n",
    "    \"\"\"\n",
    "    Computes similarities between user prompts and assistant's previous follow-up questions.\n",
    "\n",
    "    Args:\n",
    "        conversation_data (list): The list of conversation data dictionaries.\n",
    "    \"\"\"\n",
    "    for i, item in enumerate(conversation_data):\n",
    "        # For idx 0 (first user prompt), there is no previous assistant follow-up to compare\n",
    "        if i == 0:\n",
    "            item['similarity'] = None\n",
    "            continue\n",
    "\n",
    "        current_user_label = item['user_label']\n",
    "        current_user_text = item['clean_user_text']\n",
    "\n",
    "        # Aggregate assistant follow-up questions up to Assistant Prompt N-1\n",
    "        all_previous_followups = []\n",
    "        for prev_item in conversation_data[:i]:\n",
    "            assistant_followups = prev_item['assistant_methods'].get('Follow-Up Questions', [])\n",
    "            all_previous_followups.extend(assistant_followups)\n",
    "\n",
    "        # Compute similarity between current user prompt and each follow-up question\n",
    "        similarities = []\n",
    "        for fq in all_previous_followups:\n",
    "            fq_text = fq['text']\n",
    "            sim_score = compute_similarity(current_user_text, fq_text)\n",
    "            similarities.append((fq, sim_score))\n",
    "\n",
    "        # Find the highest similarity score\n",
    "        if similarities:\n",
    "            similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "            highest_score = similarities[0][1]\n",
    "            most_similar_question_dict = similarities[0][0]\n",
    "            most_similar_question_text = most_similar_question_dict['text']\n",
    "            associated_methods = most_similar_question_dict['methods']\n",
    "\n",
    "            # Store the similarity data\n",
    "            item['similarity'] = {\n",
    "                'next_user_label': current_user_label,\n",
    "                'most_similar_question_text': most_similar_question_text,\n",
    "                'associated_methods': associated_methods,\n",
    "                'similarity_score': highest_score\n",
    "            }\n",
    "        else:\n",
    "            item['similarity'] = None  # No previous follow-up questions to compare\n",
    "\n",
    "def export_results_verbose(conversation_data):\n",
    "    \"\"\"\n",
    "    Exports the results by printing the conversation data and comparison results.\n",
    "\n",
    "    Args:\n",
    "        conversation_data (list): The list of conversation data dictionaries.\n",
    "    \"\"\"\n",
    "    for item in conversation_data:\n",
    "        idx = item['idx']\n",
    "        user_label = item['user_label']\n",
    "        user_text = item['user_text']\n",
    "        asst_label = item['asst_label']\n",
    "        asst_text = item['asst_text']\n",
    "        assistant_methods = item['assistant_methods']\n",
    "        segmented = item['segmented']\n",
    "        similarity = item.get('similarity')\n",
    "\n",
    "        print(f\"{user_label}:\\n{user_text}\")\n",
    "        print(f\"{asst_label}:\\n{asst_text}\")\n",
    "\n",
    "        if similarity:\n",
    "            print(f\"Comparing {similarity['next_user_label']} to assistant's previous follow-up questions...\\n\")\n",
    "            print(f\"Most similar follow-up question:\")\n",
    "            print(f\"Text: {similarity['most_similar_question_text']}\")\n",
    "            print(f\"Socratic Methods: {similarity['associated_methods']}\")\n",
    "            print(f\"Similarity score: {similarity['similarity_score']:.4f}\\n\")\n",
    "        else:\n",
    "            print(\"No previous follow-up questions to compare with.\\n\")\n",
    "        \n",
    "        print(\"Segmented Assistant Response:\")\n",
    "\n",
    "        for cat, seg_text in segmented.items():\n",
    "            print(f\"  {cat}:\\n    {seg_text}\\n\")\n",
    "\n",
    "            if cat in [\"Selected Principle(s)\", \"Follow-Up Questions\"] and seg_text:\n",
    "                if cat == \"Selected Principle(s)\":\n",
    "                    methods = assistant_methods.get('Selected Principle(s)', [])\n",
    "                    print(f\"    Identified Socratic Methods: {methods}\\n\")\n",
    "                elif cat == \"Follow-Up Questions\":\n",
    "                    followup_questions = assistant_methods.get('Follow-Up Questions', [])\n",
    "                    print(\"    Individual Follow-Up Questions:\")\n",
    "                    for question_dict in followup_questions:\n",
    "                        q_num = question_dict['number']\n",
    "                        q_methods = question_dict['methods']\n",
    "                        q_text = question_dict['text']\n",
    "                        print(f\"      Question {q_num}:\")\n",
    "                        print(f\"        Socratic Methods: {q_methods}\")\n",
    "                        print(f\"        Text: {q_text}\\n\")\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "def export_results(conversation_data):\n",
    "    \"\"\"\n",
    "    Exports the results by printing only the specified information:\n",
    "        1) Socratic Methods and Similarity scores of user's prompts\n",
    "        2) Identified Socratic Methods of reformulated question\n",
    "        3) Socratic Methods of Follow-Up Questions\n",
    "\n",
    "    Args:\n",
    "        conversation_data (list): The list of conversation data dictionaries.\n",
    "    \"\"\"\n",
    "    for item in conversation_data:\n",
    "        idx = item['idx']\n",
    "        user_label = item['user_label']\n",
    "        user_text = item['user_text']\n",
    "        assistant_methods = item['assistant_methods']\n",
    "        similarity = item.get('similarity')\n",
    "\n",
    "        print(f\"{user_label}:\\n{user_text}\\n\")\n",
    "\n",
    "        # 1) Socratic Methods and Similarity scores of user's prompts\n",
    "        if similarity:\n",
    "            next_user_label = similarity['next_user_label']\n",
    "            similarity_score = similarity['similarity_score']\n",
    "            most_similar_question_text = similarity['most_similar_question_text']\n",
    "            associated_methods = similarity['associated_methods']\n",
    "\n",
    "            print(f\"Comparing {next_user_label} to assistant's previous follow-up questions...\\n\")\n",
    "            print(f\"Most similar follow-up question:\")\n",
    "            print(f\"Text: {most_similar_question_text}\")\n",
    "            print(f\"Socratic Methods: {associated_methods}\")\n",
    "            print(f\"Similarity score: {similarity_score:.4f}\\n\")\n",
    "        else:\n",
    "            print(\"No previous follow-up questions to compare with.\\n\")\n",
    "\n",
    "        # 2) Identified Socratic Methods of reformulated question\n",
    "        socratic_methods_reformulation = assistant_methods.get('Socratic Reformulation', [])\n",
    "        if socratic_methods_reformulation:\n",
    "            print(f\"Identified Socratic Methods in Reformulated Question: {socratic_methods_reformulation}\\n\")\n",
    "\n",
    "        # 3) Socratic Methods of Follow-Up Questions\n",
    "        followup_questions = assistant_methods.get('Follow-Up Questions', [])\n",
    "        if followup_questions:\n",
    "            print(\"Socratic Methods of Follow-Up Questions:\")\n",
    "            for question_dict in followup_questions:\n",
    "                q_num = question_dict['number']\n",
    "                q_methods = question_dict['methods']\n",
    "                print(f\"  Question {q_num} Socratic Methods: {q_methods}\")\n",
    "            print()\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "def check_socratic_system_prompt(file_path):\n",
    "    \"\"\"\n",
    "    Checks if the conversation file at file_path starts with the Socratic system prompt,\n",
    "    by searching for specific keywords in the beginning of the file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the conversation file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all keywords are found in the beginning of the file, False otherwise.\n",
    "    \"\"\"\n",
    "    keywords = [\n",
    "        \"You are a Socratic AI assistant\",\n",
    "        \"Integration of the Mixed Socratic Prompting Approach\",\n",
    "        \"Response Structure for Any User Query\"\n",
    "    ]\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            # Read the first 10000 characters (or adjust as needed)\n",
    "            beginning_text = f.read(10000)\n",
    "\n",
    "        # Check if all keywords are present in the beginning text\n",
    "        return all(keyword in beginning_text for keyword in keywords)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return False\n",
    "\n",
    "def main(verbose=False):\n",
    "    # Replace with your actual file path\n",
    "    file_path = r\"C:\\Users\\yunkai.sun\\Box\\SM_Assessment\\Submissions\\Unal_Mustafa\\SiC Dislocation Analysis\\SiC - Socratic Approach.txt\"\n",
    "    file_path = r\"C:\\Users\\yunkai.sun\\Box\\SM_Assessment\\Submissions\\Yunkai_Sun\\Raw data\\SM-4 Practical Application, YKS, Argo â–¡ Argonne National Laboratory_5-56-12PM_02-22-2025.txt\"\n",
    "    \n",
    "    if not check_socratic_system_prompt(file_path):\n",
    "        print(\"The conversation file does not follow the Socratic system prompt.\")\n",
    "        return  # Exit or handle accordingly\n",
    "\n",
    "    paired_conversation = segment_conversation_preserve_paragraphs(file_path)\n",
    "    #del paired_conversation[0]  # Remove initial system prompt if necessary\n",
    "\n",
    "    # Define the Socratic methods list\n",
    "    \n",
    "    # Process conversation and build data structures\n",
    "    conversation_data = process_conversation(paired_conversation, socratic_methods)\n",
    "\n",
    "    # Compute similarities\n",
    "    compute_similarities(conversation_data)\n",
    "\n",
    "    # Export results\n",
    "    if verbose:\n",
    "        export_results_verbose(conversation_data)\n",
    "    else:\n",
    "        export_results(conversation_data)\n",
    "\n",
    "socratic_methods = [\n",
    "        'Definition',\n",
    "        'Generalization',\n",
    "        'Induction',\n",
    "        'Elenchus',\n",
    "        'Hypothesis Elimination',\n",
    "        'Maieutics',\n",
    "        'Dialectic',\n",
    "        'Recollection',\n",
    "        'Analogy',\n",
    "        'Irony'\n",
    "    ]   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    verbose_main = False\n",
    "    #verbose_main = True\n",
    "    main(verbose_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a986ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
